import logging

from dotenv import load_dotenv
from fastapi import FastAPI

from app.jobs.stock_news.analyzer.QuickNewsAnalyzer import QuickNewsAnalyzer
from app.jobs.stock_news.pipeline.manager import PipelineManager
from app.routers import stock, stock_news, report

from contextlib import asynccontextmanager
from fastapi import FastAPI
import uvicorn
from uvicorn.middleware.proxy_headers import ProxyHeadersMiddleware


# [Lifespan] ì•± ì¼œì§ˆ ë•Œ ì›Œì»¤ ì¶œê·¼ -> êº¼ì§ˆ ë•Œ ì›Œì»¤ í‡´ê·¼ ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì‹œì‘: íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ìƒì„± ë° ì›Œì»¤ ê°€ë™
    print("ğŸ­ ì‹œìŠ¤í…œ ê°€ë™: íŒŒì´í”„ë¼ì¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")

    load_dotenv()
    from langchain_openai import ChatOpenAI
    chat_model = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    analyzer = QuickNewsAnalyzer(chat_model)

    manager = PipelineManager(analyzer = analyzer)
    await manager.start(worker_count=3)

    # ì•± ì „ì²´ì—ì„œ ì“¸ ìˆ˜ ìˆê²Œ stateì— ì €ì¥
    app.state.pipeline_manager = manager

    yield  # ì•± ì‹¤í–‰ ì¤‘...

    # ì¢…ë£Œ: ì›Œì»¤ í‡´ê·¼ ë° ì •ë¦¬
    print("ğŸ›‘ ì‹œìŠ¤í…œ ì¢…ë£Œ: íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì¤‘...")
    await manager.stop()


app = FastAPI(lifespan=lifespan, title="AI Stock Analyst Agent", root_path="/ai")
app.add_middleware(ProxyHeadersMiddleware, trusted_hosts=["*"])

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
)


# ë¼ìš°í„° ë“±ë¡
app.include_router(stock_news.router, prefix="/api/news", tags=["News"])
app.include_router(stock.router, prefix="/api/stock", tags=["Stock"])
app.include_router(report.router, prefix="/api/report", tags=["Report"])


if __name__ == "__main__":
    import uvicorn

    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)