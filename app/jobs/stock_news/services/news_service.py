import logging
import asyncio
from typing import List
from app.db.StockNews import StockNews
from app.services.aws_service import put_items_batch_dynamodb

logger = logging.getLogger("NewsService")


class NewsService:
    def __init__(self, crawler_factory, analyzer, concurrency_limit: int = 5):
        self.crawler_factory = crawler_factory
        self.analyzer = analyzer
        self.table_name = "StockProjectData"
        self.semaphore = asyncio.Semaphore(concurrency_limit) # ë™ì‹œ ìš”ì²­ ìˆ˜ ìžë™ ì œì–´

    async def process_news_list(self, items: List[StockNews]) -> List[StockNews]:

        if not items:
            return []

        # í¬ë¡¤ë§: ë‚´ìš©ì´ ì—†ëŠ” ì•„ì´í…œë§Œ ê³¨ë¼ì„œ í¬ë¡¤ë§ íƒœìŠ¤í¬ ìƒì„±
        crawl_tasks = [self._fetch_content_safe(item) for item in items if not item.content]

        if crawl_tasks:
            # ë³‘ë ¬ ì‹¤í–‰ (ë‚´ë¶€ì—ì„œ semaphoreë¡œ ì†ë„ ì¡°ì ˆë¨)
            await asyncio.gather(*crawl_tasks)

        # ìœ íš¨ì„± ê²€ì‚¬ :í¬ë¡¤ë§ ì‹¤íŒ¨í–ˆê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì€ ê²ƒ ì œê±°
        valid_items = [item for item in items if self._is_valid(item.content)]

        if not valid_items:
            logger.info(f"âš ï¸ ì²˜ë¦¬í•  ìœ íš¨í•œ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. (ìš”ì²­: {len(items)}ê±´)")
            return []

        # AI ë¶„ì„ (Analysis)
        logger.info(f"ðŸ§  AI ë¶„ì„ ì‹œìž‘: {len(valid_items)}ê±´")
        try:
            # analyzer.analyze_batchëŠ” ë¦¬ìŠ¤íŠ¸ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
            analysis_results = self.analyzer.analyze_batch(valid_items)

            # ê²°ê³¼ ë§¤í•‘
            for item, analysis in zip(valid_items, analysis_results):
                item.sentiment = analysis.get('sentiment', 'neutral')
                item.impact_score = analysis.get('importance', 0)
                item.ai_summary = analysis.get('summary', '')

        except Exception as e:
            logger.error(f"âŒ AI ë¶„ì„ ë‹¨ê³„ ì—ëŸ¬: {e}")
            # ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì—¬ê¸°ì„œ ì¤‘ë‹¨í•˜ê³  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (DB ì €ìž¥ X)
            return []

        # DB ì €ìž¥
        try:
            # StockNews ê°ì²´ë¥¼ DynamoDB JSON í¬ë§·ìœ¼ë¡œ ë³€í™˜
            items_to_save = [item.to_dynamodb_item() for item in valid_items]
            await put_items_batch_dynamodb(table_name=self.table_name, items=items_to_save)
            logger.info(f"ðŸ’¾ DB ì €ìž¥ ì™„ë£Œ: {len(valid_items)}ê±´")
        except Exception as e:
            logger.error(f"âŒ DynamoDB ì €ìž¥ ì‹¤íŒ¨: {e}")

        return valid_items # ë¬´ì¡°ê±´ ë°˜í™˜: toolì—ì„œ í›„ì† ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡

    async def _fetch_content_safe(self, item: StockNews):
        async with self.semaphore:
            try:
                crawler = self.crawler_factory.get_crawler(item.source)

                content = await crawler.fetch(item.url)
                item.content = content

            except Exception as e:
                logger.warning(f"âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨ ({item.source}): {item.url} -> {e}")
                item.content = None

    def _is_valid(self, content: str) -> bool:
        if not content:
            return False
        if len(content.strip()) < 50:  # 50ìž ë¯¸ë§Œì€ ìœ ì˜ë¯¸í•œ ì •ë³´ê°€ ì•„ë‹ í™•ë¥  ë†’ìŒ
            return False
        return True